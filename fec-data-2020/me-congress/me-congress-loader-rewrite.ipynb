{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maine Congress overview script\n",
    "\n",
    "This file pulls in individual contributions to all Senate committees as well as independent expenditures to support or oppose the candidates and party-coordinated expenditures to support or oppose the candidates.\n",
    "\n",
    "The data fuels a dashboard that contains an overview of the race so far. It also provides the information to reconcile itemized contribution data with campaign totals available from the FEC.\n",
    "\n",
    "All of the files are written to a repository at data.world, where they are combined together in SQL scripts to fuel Tableau Public dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import config\n",
    "import os\n",
    "import datadotworld as dw\n",
    "import time\n",
    "import pygsheets\n",
    "import http.client\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "##Schedule_a API guide: https://api.open.fec.gov/developers/#/receipts/get_schedules_schedule_a_Ëœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define functions\n",
    "def get_cands(state,cycle):\n",
    "    \n",
    "    state = state.split(',')\n",
    "    cycle = cycle.split(',')\n",
    "    end = 'https://api.open.fec.gov/v1/candidates/search'\n",
    "\n",
    "    for state in state:\n",
    "\n",
    "        for cycle in cycle:\n",
    "\n",
    "            params = {'election_year':cycle\n",
    "                     ,'state':state\n",
    "                     ,'api_key':config.fec_key}\n",
    "\n",
    "            r = requests.get(end,params=params).json()\n",
    "\n",
    "            cand_all = []\n",
    "            cands = json_normalize(data=r['results']) \\\n",
    "                                     [['candidate_id'\n",
    "                                        ,'name'\n",
    "                                        ,'party_full'\n",
    "                                        ,'incumbent_challenge_full'\n",
    "                                        ,'office_full'\n",
    "                                        ,'first_file_date'\n",
    "                                      ]]\n",
    "\n",
    "            comm = json_normalize(data=r['results'],\n",
    "                   record_path='principal_committees') \\\n",
    "                    [['candidate_ids'\n",
    "                       ,'committee_id'\n",
    "                       ,'name']]\n",
    "\n",
    "            comm['candidate_ids'] = comm['candidate_ids'].str[0]\n",
    "\n",
    "            #Merge candidate and committee lookups\n",
    "            cands = cands.merge(comm,left_on='candidate_id',right_on='candidate_ids')\n",
    "\n",
    "            #Rename cols\n",
    "            colnm = {\n",
    "                'name_x':'candidate_name'\n",
    "                ,'name_y':'committee_name'\n",
    "            }\n",
    "            cands.rename(columns=colnm,inplace=True)\n",
    "            cands.drop(columns='candidate_ids',inplace=True)\n",
    "\n",
    "            cand_all.append(cands)\n",
    "\n",
    "    cand_all = pd.concat(cand_all,sort=False,ignore_index=True).drop_duplicates()\n",
    "\n",
    "    return cand_all\n",
    "\n",
    "def get_committees(names):\n",
    "\n",
    "    names = names.split(',')\n",
    "    \n",
    "    comms = []\n",
    "    end = 'https://api.open.fec.gov/v1/names/committees'\n",
    "\n",
    "    for name in names:\n",
    "\n",
    "        params = {'q':name\n",
    "                 ,'api_key':config.fec_key}\n",
    "\n",
    "        r = requests.get(end,params=params).json()\n",
    "\n",
    "        comm = json_normalize(data=r['results'])\n",
    "\n",
    "        comms.append(comm)\n",
    "\n",
    "    comm_all = pd.concat(comms,sort=False,ignore_index=True).drop_duplicates()\n",
    "\n",
    "    return comm_all\n",
    "\n",
    "\n",
    "def get_itemized(cycle,cands):\n",
    "    \n",
    "    def get_unitem(cycle,cands,commid):\n",
    "        \n",
    "        end = 'https://api.open.fec.gov/v1/committee/'\n",
    "        params = {\n",
    "            'api_key':config.fec_key\n",
    "            ,'cycle':cycle\n",
    "            ,'per_page':'100'\n",
    "            ,'committee_id':commid\n",
    "        }\n",
    "        #Collect unitemized contributions\n",
    "        r = requests.get(end+commid+'/totals',params=params).json()\n",
    "        udf = json_normalize(r['results'])\n",
    "        return udf\n",
    "\n",
    "    cycle = cycle.split(',')\n",
    "    end = 'https://api.open.fec.gov/v1/schedules/schedule_a/'\n",
    "    ids = cands['committee_id']\n",
    "    dfs = []\n",
    "    udfs = []\n",
    "    page_count = 0\n",
    "    cand_count = len(cands)\n",
    "\n",
    "    for idx, commid in enumerate(ids):\n",
    "        \n",
    "        params = {\n",
    "            'per_page':'100'\n",
    "            ,'sort':'contribution_receipt_date'\n",
    "            ,'api_key':config.fec_key\n",
    "            ,'is_individual':'true'\n",
    "            ,'two_year_transaction_period':cycle\n",
    "            ,'last_index':[]\n",
    "            ,'last_contribution_receipt_date':[]\n",
    "            ,'committee_id':commid\n",
    "        }\n",
    "        \n",
    "        udfs.append(get_unitem(cycle,cands,commid))\n",
    "        \n",
    "        #Initialize Schedule A request\n",
    "        r = requests.get(end,params=params).json()\n",
    "\n",
    "        candidate = cands['candidate_name'][idx]\n",
    "\n",
    "        try:\n",
    "            pages = r['pagination']['pages']\n",
    "        except:\n",
    "            pages = 0\n",
    "\n",
    "        if pages == 0:\n",
    "            df = json_normalize(r['results'])\n",
    "            dfs.append(df)\n",
    "        else:\n",
    "            page_count = page_count + pages\n",
    "            while r['pagination']['last_indexes'] is not None:\n",
    "\n",
    "                df = json_normalize(r['results'])\n",
    "                dfs.append(df)\n",
    "\n",
    "                last_index = r['pagination']['last_indexes']['last_index']\n",
    "                last_date = r['pagination']['last_indexes']['last_contribution_receipt_date']\n",
    "\n",
    "                params.update([('last_index',last_index)\n",
    "                            ,('last_contribution_receipt_date',last_date)])\n",
    "\n",
    "                r = requests.get(end,params=params).json()\n",
    "        \n",
    "    print(f'{page_count} pages for {cand_count} candidates')\n",
    "\n",
    "    #After for loop, concatenate dfs\n",
    "    df = pd.concat(dfs,sort=False,ignore_index=True).drop_duplicates(subset='transaction_id')\n",
    "    ustore = pd.concat(udfs,sort=False,ignore_index=True).drop_duplicates()\n",
    "    \n",
    "    #Clean dataframe\n",
    "    df['contributor_zip'] = df['contributor_zip'].str[:5]\n",
    "\n",
    "    #Filter to is_individual and no memoed subtotal\n",
    "    df=df[(df['is_individual']==True)|(df['memoed_subtotal']==False)]\n",
    "    \n",
    "    #Transform unitemized table, based on df structure\n",
    "    cols=df.columns.values.tolist()\n",
    "    udf = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    targetcols = ['committee.name'\n",
    "                ,'committee.party_full'\n",
    "                ,'committee_id'\n",
    "                ,'contribution_receipt_amount'\n",
    "                ,'contribution_receipt_date'\n",
    "                ,'fec_election_type_desc']\n",
    "    \n",
    "    sourcecols = ['committee_name'\n",
    "                ,'party_full'\n",
    "                ,'committee_id'\n",
    "                ,'individual_unitemized_contributions'\n",
    "                ,'coverage_end_date'\n",
    "                ,'last_report_type_full']\n",
    "    \n",
    "    udf[targetcols] = ustore[sourcecols]\n",
    "    \n",
    "    #Add labels\n",
    "    udf['contributor_name'] = 'Unitemized individual contributions'\n",
    "    udf['entity_type'] = 'IND'\n",
    "    \n",
    "    #Combine dataframes\n",
    "    df = pd.concat([df,udf],sort=False,ignore_index=True)\n",
    "    \n",
    "    #Parse datetime\n",
    "    df['contribution_receipt_date'] = df['contribution_receipt_date'].str.split('T', expand=True)[0]\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_ies(cycle,cands):\n",
    "\n",
    "    cycle = cycle.split(',')\n",
    "    end = 'https://api.open.fec.gov/v1/schedules/schedule_e/'\n",
    "    ids = cands['candidate_id']\n",
    "    dfs = []\n",
    "\n",
    "    for idx, item in enumerate(ids):\n",
    "\n",
    "        params = {\n",
    "            'per_page':'100'\n",
    "            ,'api_key':config.fec_key\n",
    "            ,'cycle':cycle\n",
    "            ,'last_index':[]\n",
    "            ,'last_expenditure_date':[]\n",
    "            ,'candidate_id':item\n",
    "        }\n",
    "\n",
    "        r = requests.get(end,params=params).json()\n",
    "\n",
    "        candidate = cands['candidate_name'][idx]\n",
    "\n",
    "        try:\n",
    "            pages = str(r['pagination']['pages'])\n",
    "        except:\n",
    "            pages = 0\n",
    "\n",
    "        if pages == 0:\n",
    "            df = json_normalize(r['results'])\n",
    "            dfs.append(df)\n",
    "        else:\n",
    "            while r['pagination']['last_indexes'] is not None:\n",
    "\n",
    "                df = json_normalize(r['results'])\n",
    "                dfs.append(df)\n",
    "\n",
    "                last_index = r['pagination']['last_indexes']['last_index']\n",
    "                last_date = r['pagination']['last_indexes']['last_expenditure_date']\n",
    "\n",
    "                params.update([('last_index',last_index)\n",
    "                                  ,('last_expenditure_date',last_date)])\n",
    "\n",
    "                r = requests.get(end,params=params).json()\n",
    "\n",
    "    #After for loop, concatenate dfs\n",
    "    df = pd.concat(dfs,sort=False,ignore_index=True).drop_duplicates(subset='transaction_id')\n",
    "\n",
    "    #Clean dataframe\n",
    "    df['commiteee.zip'] = df['committee.zip'].str[:5]\n",
    "    df['expenditure_date'] = df['expenditure_date'].str.split('T', expand=True)[0]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_coordinated(cycle,cands):\n",
    "    \n",
    "    cycle = cycle.split(',')\n",
    "    end = 'https://api.open.fec.gov/v1/schedules/schedule_f/'\n",
    "    ids = cands['candidate_id']\n",
    "    dfs = []\n",
    "\n",
    "    for i, item in enumerate(ids):\n",
    "\n",
    "        params = {\n",
    "            'per_page':'100'\n",
    "            ,'api_key':config.fec_key\n",
    "            ,'two_year_transaction_period':cycle\n",
    "            ,'page':1\n",
    "            ,'candidate_id':item\n",
    "        }\n",
    "\n",
    "        r = requests.get(end,params=params).json()\n",
    "\n",
    "        current_pg = r['pagination']['page']\n",
    "        all_pgs = r['pagination']['pages']\n",
    "\n",
    "        candidate = cands['candidate_name'][i]\n",
    "\n",
    "        for page in range(all_pgs):\n",
    "                \n",
    "                params.update([('page',page+1)])\n",
    "                r = requests.get(end,params=params).json()\n",
    "\n",
    "                df = json_normalize(r['results'])\n",
    "                dfs.append(df)\n",
    "\n",
    "    #After for loop, concatenate dfs\n",
    "    df = pd.concat(dfs,sort=False,ignore_index=True).drop_duplicates(subset='transaction_id')\n",
    "\n",
    "    #Clean dataframe\n",
    "    df['commiteee.zip'] = df['committee.zip'].str[:5]\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_summary(cycle,cands):\n",
    "    \n",
    "    cycle = cycle.split(',')\n",
    "    end = 'https://api.open.fec.gov/v1/committee/'\n",
    "    ids = cands['committee_id']\n",
    "    dfs = []\n",
    "\n",
    "    for idx, item in enumerate(ids):\n",
    "        \n",
    "        params = {\n",
    "            'api_key':config.fec_key\n",
    "            ,'cycle':cycle\n",
    "            ,'per_page':'100'\n",
    "            ,'committee_id':item\n",
    "        }\n",
    "\n",
    "        r = requests.get(end+item+'/totals',params=params).json()\n",
    "        \n",
    "        df = json_normalize(r['results'])\n",
    "        dfs.append(df)\n",
    "\n",
    "    #After for loop, concatenate dfs\n",
    "    df = pd.concat(dfs,sort=False,ignore_index=True).drop_duplicates()\n",
    "\n",
    "    return df\n",
    "\n",
    "def write_cands(df):\n",
    "    with dw.open_remote_file('darrenfishell/2020-election-repo','candidate_committee_lookup.csv') as w:\n",
    "        df.to_csv(w,index=False)\n",
    "\n",
    "def write_indiv(df):\n",
    "    results = dw.query('darrenfishell/2020-election-repo', 'SELECT * FROM individual_congressional_contributions')\n",
    "    test = len(results.dataframe) < len(df)\n",
    "    if test:\n",
    "        with dw.open_remote_file('darrenfishell/2020-election-repo','individual-congressional-contributions.csv') as w:\n",
    "            df.to_csv(w,index=False)\n",
    "    return test\n",
    "\n",
    "def write_summary(df):            \n",
    "    results = dw.query('darrenfishell/2020-election-repo', 'SELECT * FROM congress_financial_summaries')\n",
    "    test = sum(results.dataframe['receipts']) < len(df['receipts'])\n",
    "    if test:\n",
    "        with dw.open_remote_file('darrenfishell/2020-election-repo','congress_financial_summaries.csv') as w:\n",
    "            df.to_csv(w,index=False)\n",
    "    return test\n",
    "\n",
    "def write_ies(df):       \n",
    "    results = dw.query('darrenfishell/2020-election-repo', 'SELECT * FROM congress_independent_expenditures')\n",
    "    test = len(results.dataframe) < len(df)\n",
    "    if test:\n",
    "        with dw.open_remote_file('darrenfishell/2020-election-repo','congress-independent-expenditures.csv') as w:\n",
    "            df.to_csv(w,index=False)\n",
    "    return test\n",
    "\n",
    "def write_coord(df):\n",
    "    results = dw.query('darrenfishell/2020-election-repo', 'SELECT * FROM congress_party_coordinated_expenditures')\n",
    "    test = len(results.dataframe) < len(df)\n",
    "    if test:\n",
    "        with dw.open_remote_file('darrenfishell/2020-election-repo','congress-party-coordinated-expenditures.csv') as w:\n",
    "            df.to_csv(w,index=False)\n",
    "    return test\n",
    "\n",
    "def write_to_gsheet():\n",
    "    gc = pygsheets.authorize(service_file='gcreds.json')\n",
    "    conn = http.client.HTTPSConnection(\"api.data.world\")\n",
    "    headers = { 'authorization': \"Bearer \"+config.dw_key }\n",
    "    \n",
    "    sheets_to_dw = [['maine-congress-2020','e2b1bde2-1e60-4d49-bd31-da5aa7ce0611',1],\n",
    "                    ['maine-congress-2020','026e8f40-d10e-4324-8b45-80dbc0e61627',0]]\n",
    "\n",
    "    for idx, sheet in enumerate(sheets_to_dw):\n",
    "        \n",
    "        sheet = [x[0] for x in sheets_to_dw][idx]\n",
    "        queryid = [x[1] for x in sheets_to_dw][idx]\n",
    "        gsh_idx = [x[2] for x in sheets_to_dw][idx]\n",
    "        \n",
    "        #Retrieve query\n",
    "        conn.request(\"GET\", \"/v0/queries/\"+queryid, headers=headers)\n",
    "        data = conn.getresponse().read()\n",
    "        #Execute Query\n",
    "        results = dw.query('darrenfishell/2020-election-repo',json.loads(data)['body']).dataframe\n",
    "\n",
    "        #Prepare to load into Google Sheets\n",
    "        sh = gc.open(sheet)\n",
    "        wks = sh.worksheet('index',gsh_idx)\n",
    "        wks.clear()\n",
    "        wks.rows = results.shape[0]\n",
    "        wks.set_dataframe(results,start='A1',nan='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 18 candidate records to data.world.\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Set state(s) and cycle(s) for candidate search\n",
    "state='ME'\n",
    "cycle='2020'\n",
    "\n",
    "#Query candidates and write to data.world\n",
    "try:\n",
    "    cands = get_cands(state,cycle)\n",
    "    write_cands(cands)\n",
    "    length = len(cands)\n",
    "    print(f'Wrote {length} candidate records to data.world.')\n",
    "except:\n",
    "    print('Candidate lookup query failed.')\n",
    "\n",
    "\n",
    "#Get - write contribution pairs\n",
    "getwrite = {\n",
    "    get_itemized: write_indiv,\n",
    "    get_summary: write_summary,\n",
    "    get_ies: write_ies,\n",
    "    get_coordinated: write_coord\n",
    "}\n",
    "\n",
    "#Filename - input pairs\n",
    "files_input = {\n",
    "    'itemized contributions':[cycle,cands],\n",
    "    'campaign summary':[cycle,cands],\n",
    "    'independent expenditures':[cycle,cands],\n",
    "    'party coordinated expenditures':[cycle,cands]\n",
    "}\n",
    "\n",
    "#List of functions, filenames and inputs to unpack\n",
    "files = [x[0] for x in list(files_input.items())]\n",
    "params = [x[1] for x in list(files_input.items())]\n",
    "\n",
    "#Iterate over all get-write functions, with TRY\n",
    "for idx, (get,write) in enumerate(getwrite.items()):\n",
    "    \n",
    "    #Set filename\n",
    "    file = files[idx]\n",
    "    \n",
    "    try:\n",
    "        #Run function r, return dataframes\n",
    "        df = get(*params[idx])\n",
    "        \n",
    "        #Set filename and df length\n",
    "        length = len(df)\n",
    "        file = files[idx]\n",
    "\n",
    "        #Execute write functions to write to datadotworld\n",
    "        new = write(df)\n",
    "        \n",
    "        if new:\n",
    "            print(f'Wrote {length} records to {file}')\n",
    "        else:\n",
    "            print(f'No update to {file}.')\n",
    "\n",
    "    except:       \n",
    "        print(f'Failed to write {file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote to GSheets\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    write_to_gsheet()\n",
    "    print('Wrote to GSheets')\n",
    "except:\n",
    "    print('Failed to write to GSheet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
